<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Jędrzej Orbik</title>
  
  <meta name="author" content="Jędrzej Orbik">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Jędrzej Orbik</name>
              </p>
              <p>Currently a Robotics Software Engineer at Intrinsic, an Alphabet company. Previously a research engineer at
                <a href="http://rail.eecs.berkeley.edu">UC Berkeley</a> advised by professor Sergey Levine. Experienced robotics software engineer with a strong background in motion planning, robot perception, and deep reinforcement learning. Skilled in designing and implementing high-quality software for robotic automation systems. Proven ability to work closely with customers, scope projects, and lead development teams towards successful production deployments.
              </p>
              <p style="text-align:center">
                <!-- <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp
                <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                <!-- <a href="https://scholar.google.com/citations?hl=en&user=jktWnL8AAAAJ">Google Scholar</a> &nbsp/&nbsp -->
                <a href="data/JedrzejOrbik-CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://twitter.com/JedrzejOrbik">Twitter</a> &nbsp/&nbsp
                <a href="https://bsky.app/profile/jedrzejorbik.bsky.social">Bluesky</a> &nbsp/&nbsp
                <a href="https://github.com/jborbik/">GitHub</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/jorbik.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/jorbik.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                Previously, I was a robotics researcher specializing in deep reinforcement learning, transfer learning, and autonomous skill acquisition for robotic manipulation.
                My research focused on developing sample-efficient learning methods that enable robots to acquire complex manipulation skills from prior data and direct experience, without requiring extensive human intervention or environment resets.
                My work encompassed autonomous mobile manipulation, robust inverse reinforcement learning for dexterous hands, and human-to-robot skill transfer using vision-based frameworks.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two">
                <img src="images/ariel.gif" width=160, height=160></img>
                </div>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2207.04703">
                <papertitle>Don't Start From Scratch: Leveraging Prior Data to Automate Robotic Reinforcement Learning</papertitle>
              </a>
              <br>
              Homer Walke,
              Jonathan Yang,
              Albert Yu,
              <a href="https://aviralkumar2907.github.io/">Aviral Kumar</a>,
              <strong>Jędrzej Orbik</strong>,
              <a href="https://www.avisingh.org/">Avi Singh</a>,
              <a href="https://people.eecs.berkeley.edu/~svlevine/">Sergey Levine</a>,
              <br>
              <em>Conference on Robot Learning (CoRL)</em>, 2022
              <br>
              <em>RSS Workshop on Learning from Diverse, Offline Data</em>, 2022
              <br>
              <a href="https://arxiv.org/abs/2207.04703">arXiv</a> /
              <a href="https://sites.google.com/view/ariel-berkeley">website</a>
              <p></p>
              <p>We demonstrate that incorporating prior data into robotic reinforcement learning enables 
                 autonomous learning, substantially improves sample-efficiency of learning, and enables better 
                 generalization. Our method learns new robotic manipulation skills directly from image observations 
                 and with minimal human intervention to reset the environment. 
              </p>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two">
                  <img src="images/relmm.png" width=160, height=160>
                </div>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://sites.google.com/view/relmm">
                <papertitle>Fully Autonomous Real-World Reinforcement Learning with Applications to Mobile Manipulation</papertitle>
              </a>
              <br>
              <a href="https://charlesjsun.github.io/">Charles Sun*</a>,
              <strong>Jędrzej Orbik*</strong>,
              <a href="https://twitter.com/ColinearDevin">Coline Devin</a>, 
              <a href="https://byang.org/">Brian Yang</a>,
              <a href="https://abhishekunique.github.io/">Ahbishek Gupta</a>, 
              <a href="https://www.fracturedplane.com/">Glen Berseth</a>, 
              and <a href="https://people.eecs.berkeley.edu/~svlevine/">Sergey Levine</a>
              <!-- Coline Devin, Brian Yang, Abhishek Gupta, Glen Berseth, and Sergey Levine -->
              <br>
              <em>Conference on Robot Learning (CoRL)</em>, 2021
              <br>
              <a href="https://arxiv.org/abs/2107.13545">arXiv</a> /
              <a href="https://bair.berkeley.edu/blog/2023/01/20/relmm/">blog post</a> /
              <a href="https://sites.google.com/view/relmm">website</a> /
              <a href="https://github.com/charlesjsun/ReLMM">code</a>
              <br>
              <p>
                We propose a reinforcement learning system that can learn mobile manipulation tasks continuously in the real world 
                without any environment instrumentation, without human intervention, and without access to privileged information, 
                such as maps, objects positions, or a global view of the environment.
              </p>
            </td>
          </tr> 
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two">
                <img src="images/irl-dext-hand.png" width=160, height=160></img>
                </div>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2207.04703">
                <papertitle>Inverse reinforcement learning for dexterous hand manipulation</papertitle>
              </a>
              <br>
              <strong>Jędrzej Orbik</strong>,
              <a href="https://asl.ict.tuwien.ac.at/team-dongheui-lee.html">Dongheui Lee</a>,
              <a href="https://iis.uibk.ac.at/people/agostini/">Alejandro Agostini</a>,
              <br>
              <em>IEEE International Conference on Development and Learning (ICDL)</em>, 2021
              <br>
              <a href="https://mediatum.ub.tum.de/doc/1632205/1632205.pdf">paper</a> /
              <a href="https://sites.google.com/view/irl-for-dexterous-hand">website</a> /
              <a href="https://github.com/Jendker/inverse_rl_dexterous_hand">source code</a>
              <p></p>
              <p>We identify that the learned rewards using existing IRL approaches are strongly biased towards 
                demonstrated actions due to the scarcity of samples in the vast state-action space of dexterous manipulation applications. 
                In this work we use statistical tools for random sample generation and reward normalization 
                to reduce this bias. We show that this approach improves learning stability and robustness of policies learned with the inferred reward.
              </p>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two">
                <img src="images/dext-hand-retargeting.png" width=160, height=160></img>
                </div>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2207.04703">
                <papertitle>Human hand motion retargeting for dexterous robotic hand</papertitle>
              </a>
              <br>
              <strong>Jędrzej Orbik</strong>,
              Shile Li,
              <a href="https://asl.ict.tuwien.ac.at/team-dongheui-lee.html">Dongheui Lee</a>,
              <br>
              <em>18th International Conference on Ubiquitous Robots (UR)</em>, 2021
              <br>
              <a href="https://mediatum.ub.tum.de/doc/1637161/1637161.pdf">paper</a> /
              <a href="https://sites.google.com/view/retargeting-for-dexterous-hand">website</a>
              <p></p>
              <p> We propose a low-cost framework to map the human hand motion from a single RGB-D camera to a dexterous robotic hand. 
                We incorporate neural network pose estimation and inverse kinematics for real-time hand motion retargeting. 
                Empirically, the proposed framework can successfully perform grasping task imitations.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <p align="right">
                <font size="2">
                  <a href="https://jonbarron.info/">template</a>
                  </font>
              </p>
            </td>
          </tr>
        </table>
      </td>
    </tr>
  </table>
</body>

</html>
